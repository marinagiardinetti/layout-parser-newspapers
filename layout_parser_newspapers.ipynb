{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbGanx_tVzjv"
      },
      "source": [
        "# Layout Parser - Model trained\n",
        "\n",
        "\n",
        "The model used here has been trained on BNF (Gallica)'s newspapers pages. they has been annotated and these annotations exported on COCO format.\n",
        "\n",
        "It can be used to extract the images the newspapers pages contained.\n",
        "\n",
        "The only thing to change is the paths to:\n",
        "- the model & config file (.pth & .yaml)\n",
        "- the pages you want to extract the pictures\n",
        "\n",
        "This notebook is made to be used linked to your Google Drive account. You can easily adapt it to use it with Jupyter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfbWFXAUH0l4"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install -q requests\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q opencv-python\n",
        "!pip install -q torchvision\n",
        "!pip install Pillow==9.5.0\n",
        "\n",
        "# Import necessary libraries\n",
        "import shutil\n",
        "import requests\n",
        "import glob\n",
        "import re\n",
        "import math\n",
        "import json\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Install and import layoutparser and detectron2\n",
        "#!pip install -q 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2'\n",
        "!pip install -q -U layoutparser\n",
        "\n",
        "import layoutparser as lp\n",
        "\n",
        "# Import PyTorch and empty the CUDA cache\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Print the PyTorch version\n",
        "print(torch.__version__)\n",
        "\n",
        "import requests\n",
        "\n",
        "# Define the Hugging Face repository and model files\n",
        "repo_id = \"mgiardinetti/layout-parser-newspapers\"\n",
        "config_file = \"config.yaml\"\n",
        "model_file = \"model_final.pth\"\n",
        "\n",
        "# Create a directory to save the model\n",
        "save_directory = \"/content/layout-parser-newspapers\"\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "# Download the configuration file\n",
        "config_url = f\"https://huggingface.co/{repo_id}/resolve/main/{config_file}\"\n",
        "config_path = os.path.join(save_directory, config_file)\n",
        "response = requests.get(config_url)\n",
        "with open(config_path, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "# Download the model weights\n",
        "model_url = f\"https://huggingface.co/{repo_id}/resolve/main/{model_file}\"\n",
        "model_path = os.path.join(save_directory, model_file)\n",
        "response = requests.get(model_url)\n",
        "with open(model_path, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa3ln2dUWyzb"
      },
      "outputs": [],
      "source": [
        "import layoutparser as lp\n",
        "\n",
        "# Model and configuration file paths\n",
        "model = \"/content/layout-parser-newspapers/model_final.pth\"\n",
        "config = \"/content/layout-parser-newspapers/config.yaml\"\n",
        "\n",
        "# Association id:nom for each class to detect\n",
        "labels = \"0:illustration 1:legende\"\n",
        "\n",
        "# Parse labels\n",
        "dictlabels = {}\n",
        "if labels:\n",
        "    for asso in labels.split(\" \"):\n",
        "        key, value = asso.split(\":\")\n",
        "        dictlabels[int(key)] = value\n",
        "\n",
        "# Load the model\n",
        "try:\n",
        "    if dictlabels:\n",
        "        model = lp.Detectron2LayoutModel(\n",
        "            config_path=config,\n",
        "            model_path=model,\n",
        "            label_map=dictlabels\n",
        "        )\n",
        "    else:\n",
        "        model = lp.Detectron2LayoutModel(\n",
        "            config_path=config,\n",
        "            model_path=model\n",
        "        )\n",
        "    print(\"Modèle importé\")\n",
        "except Exception as e:\n",
        "    print(f\"Le modèle n'a pas été importé: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "import cv2\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import layoutparser as lp\n",
        "\n",
        "# Define directories\n",
        "#@markdown Indiquer les chemins vers\n",
        "\n",
        "pages_directory = '/content/drive/My Drive/LP/similaires_rol/' # @param {type:\"string\"}\n",
        "extractions_path = '/content/drive/My Drive/LP/' # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "seuil_score = 0.95 # @param {type:\"string\"}\n",
        "\n",
        "# Process each page\n",
        "for page_path in glob.glob(os.path.join(pages_directory, '*.jpg')):\n",
        "    page_name = os.path.basename(page_path)\n",
        "\n",
        "    # Read and convert image\n",
        "    image = cv2.imread(page_path)\n",
        "    image = image[..., ::-1]\n",
        "\n",
        "    # Detect layout\n",
        "    layout = model.detect(image)\n",
        "    layout = [x for x in layout if x.score > seuil_score]\n",
        "    print(\"_________________Extraction of the pictures_________________\")\n",
        "\n",
        "    # Extract bounding box coordinates\n",
        "    layout_str = str(layout)\n",
        "    x1 = list(map(int, re.findall(r'x_1=(\\d+)', layout_str)))\n",
        "    y1 = list(map(int, re.findall(r'y_1=(\\d+)', layout_str)))\n",
        "    x2 = list(map(int, re.findall(r'x_2=(\\d+)', layout_str)))\n",
        "    y2 = list(map(int, re.findall(r'y_2=(\\d+)', layout_str)))\n",
        "\n",
        "    # Crop and save images\n",
        "    for i, (x1_i, y1_i, x2_i, y2_i) in enumerate(zip(x1, y1, x2, y2)):\n",
        "                img = Image.open(page_path)\n",
        "                cropped = img.crop((x1_i, y1_i, x2_i, y2_i))\n",
        "                cropped_file_name = f\"{os.path.splitext(page_name)[0]}_{i+1:02d}.jpg\"\n",
        "                cropped.save(os.path.join(extractions_path, cropped_file_name))\n"
      ],
      "metadata": {
        "id": "bVQ_ByQmx9-k"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}